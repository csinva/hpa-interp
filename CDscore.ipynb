{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run on ip-172-31-62-205\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data.sampler import RandomSampler, SequentialSampler\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from importlib import import_module\n",
    "import sys, os\n",
    "opj = os.path.join\n",
    "ope = os.path.exists\n",
    "\n",
    "this_dir = os.getcwd()\n",
    "lib_paths = [opj(this_dir, 'bestfitting/protein_clean/src'), opj(this_dir, 'CD'), opj(this_dir, 'viz')]\n",
    "for lib_path in lib_paths:\n",
    "    if lib_path not in sys.path:\n",
    "        sys.path.insert(0, lib_path) \n",
    "import train_cls_net # import Protein class\n",
    "from net import _init_paths\n",
    "from config.config import * # set directory paths (DATA_DIR, RESULT_DIR etc)\n",
    "from dataset import protein_dataset # import ProteinDataset class\n",
    "from utils.augment_util import * # import augmentation functions\n",
    "from net.loss_funcs.kaggle_metric import prob_to_result # import prob_to_result\n",
    "from net.loss_funcs.kaggle_metric import get_probs_f1_score # import get_probs_f1_score  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cd_propagate import *\n",
    "from cd import *\n",
    "import viz \n",
    "from copy import deepcopy\n",
    "from matplotlib import gridspec\n",
    "import pickle as pkl\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'viz' from '/home/ubuntu/HPA/hpa_interp/viz/viz.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(viz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set parameters and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "module = 'densenet'\n",
    "model_name = 'class_densenet121_large_dropout'\n",
    "out_dir = 'external_crop1024_focal_slov_hardlog_clean'\n",
    "train_batch_size = 36\n",
    "test_batch_size = 12\n",
    "scheduler_name = 'Adam45'\n",
    "img_size = 1536\n",
    "crop_size = 1024\n",
    "in_channels = 4\n",
    "gpus = '0' # which gpu to use\n",
    "\n",
    "folds_num = 5\n",
    "fold = 0\n",
    "num_classes = 28\n",
    "\n",
    "seed = 0\n",
    "aug_version = 2\n",
    "loss_name = 'FocalSymmetricLovaszHardLogLoss'\n",
    "predict_aug = 'default,flipud,fliplr,transpose,flipud_lr,flipud_transpose,fliplr_transpose,flipud_lr_transpose' # augmentation functions\n",
    "\n",
    "save_probs = True\n",
    "clipnorm = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define dir_args and data_args as an input to Protein class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory arguments\n",
    "dir_args = {\n",
    "    \"split_dir\": opj(DATA_DIR, \"split\"), # directory to locate labels\n",
    "    \"log_dir\": opj(RESULT_DIR, \"logs\"),\n",
    "    \"subm_dir\": opj(RESULT_DIR, \"submissions\"),\n",
    "    \"model_dir\": opj(RESULT_DIR, \"models\"),\n",
    "    \"image_check_dir\": opj(RESULT_DIR, \"image_check\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data files\n",
    "data_infos = {\n",
    "    \"model_level_name\": \"%s_i%d_aug%d_%dfolds/fold%d\" % (model_name if out_dir is None else out_dir + '_' + model_name,\n",
    "                                                             img_size, aug_version, folds_num, fold),\n",
    "}\n",
    "\n",
    "data_infos[\"train_split_file\"] = \"train_160.csv\"\n",
    "data_infos[\"valid_split_file\"] = \"valid_160.csv\"\n",
    "data_infos[\"test_split_file\"] = \"train_31072.csv\" \n",
    "\n",
    "# input of trainer.set_datasets\n",
    "data_args = {\n",
    "    \"train_split_file\": data_infos[\"train_split_file\"],\n",
    "    \"valid_split_file\": data_infos[\"valid_split_file\"],\n",
    "    \"test_split_file\": data_infos[\"test_split_file\"], \n",
    "    \"model_level_name\": data_infos[\"model_level_name\"],\n",
    "    \"result_type\": \"test\", \n",
    "    'predict_aug':predict_aug,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model and predict labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get Protein class\n",
    "trainer = train_cls_net.Protein(dir_args,\n",
    "                                train_batch_size=train_batch_size,\n",
    "                                test_batch_size=test_batch_size,\n",
    "                                seed=seed, img_size=img_size,in_channels=in_channels,\n",
    "                                save_probs=save_probs,\n",
    "                                aug_version=aug_version,\n",
    "                                num_classes=num_classes,\n",
    "                                crop_size=crop_size,\n",
    "                                clipnorm=clipnorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_channels 4\n"
     ]
    }
   ],
   "source": [
    "# directory for densenet architecture\n",
    "model = import_module(\"net.%s\" % module)\n",
    "\n",
    "# get densenet architecture pretrained on imagenet (model_name = class_densenet121_large_dropout)\n",
    "net, scheduler, loss = model.get_model(model_name,\n",
    "                                       num_classes,\n",
    "                                       loss_name,\n",
    "                                       scheduler_name=scheduler_name,\n",
    "                                       in_channels=in_channels,\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model file from: /home/ubuntu/HPA/hpa_interp/bestfitting/protein_clean/result/models/external_crop1024_focal_slov_hardlog_clean_class_densenet121_large_dropout_i1536_aug2_5folds/fold0/final.pth\n",
      "using gpu 0\n"
     ]
    }
   ],
   "source": [
    "# set directories for train, valid, test datasets and to save results\n",
    "trainer.set_datasets(data_args)\n",
    "\n",
    "# load model from model file\n",
    "trainer.load_model(net=net, epoch=None) \n",
    "\n",
    "# print model file \n",
    "print('load model file from:', trainer.get_model_file()) \n",
    "\n",
    "# number of GPUs to use\n",
    "n_gpu = trainer.setgpu(gpus)\n",
    "net = trainer.set_data_parallel(net, n_gpu=n_gpu) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/HPA/hpa_interp/bestfitting/protein_clean/data/train/images_1536\n",
      "/home/ubuntu/HPA/hpa_interp/bestfitting/protein_clean/data/train/external_v18_1536\n"
     ]
    }
   ],
   "source": [
    "###########################\n",
    "# which file to evaluate #\n",
    "data_infos[\"test_split_file\"] = \"valid_160.csv\"\n",
    "\n",
    "data_args = {\n",
    "    \"train_split_file\": data_infos[\"train_split_file\"],\n",
    "    \"valid_split_file\": data_infos[\"valid_split_file\"],\n",
    "    \"test_split_file\": data_infos[\"test_split_file\"], \n",
    "    \"model_level_name\": data_infos[\"model_level_name\"],\n",
    "    \"result_type\": \"test\", \n",
    "    'predict_aug':predict_aug,\n",
    "}\n",
    "\n",
    "trainer.set_datasets(data_args)\n",
    "###########################\n",
    "\n",
    "# test dataset and dataloader\n",
    "test_dataset = protein_dataset.ProteinDataset(trainer.test_split_file,\n",
    "                                               img_size=trainer.img_size,\n",
    "                                               is_trainset=True, # if True, save labels to self.labels \n",
    "                                               return_label=True, # if True, return labels when indexing\n",
    "                                               seed=trainer.seed,\n",
    "                                               in_channels=trainer.in_channels,\n",
    "                                               transform=None,\n",
    "                                               crop_size=trainer.crop_size,\n",
    "#                                                random_crop=trainer.seed!=0,\n",
    "                                              random_crop=trainer.seed!=1,\n",
    "                                               )\n",
    "\n",
    "test_loader = protein_dataset.DataLoader(test_dataset,\n",
    "                                         sampler=SequentialSampler(test_dataset),\n",
    "                                         batch_size=trainer.test_batch_size,\n",
    "#                                          batch_size=4,\n",
    "                                         drop_last=False,\n",
    "                                         num_workers=trainer.num_workers,\n",
    "                                         pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ready to evaluate\n"
     ]
    }
   ],
   "source": [
    "# list of augment functions\n",
    "augments = trainer.predict_aug.split(',') \n",
    "\n",
    "# pick one augmentation transform\n",
    "augment_name = augments[0]\n",
    "\n",
    "# set transform function\n",
    "test_dataset.transform = [eval('augment_%s' % augment_name)]\n",
    "\n",
    "# set directories for submission\n",
    "epoch_name = 'epoch_final'\n",
    "augment_name += '_seed%d'%seed\n",
    "sub_dir = opj(trainer.subm_dir, epoch_name, augment_name)\n",
    "\n",
    "# where to store the results\n",
    "trainer.result_csv_file = opj(sub_dir, 'results_%s.csv.gz' % data_args['test_split_file'])\n",
    "trainer.result_prob_fname = opj(sub_dir, 'prob_%s.npy' % data_args['test_split_file'])\n",
    "trainer.extract_feat_fname = opj(sub_dir, 'extract_feats_%s.npz' % data_args['test_split_file'])\n",
    "\n",
    "os.makedirs(sub_dir, exist_ok=True)\n",
    "\n",
    "# use gpu\n",
    "if trainer.gpu_flag:\n",
    "    net.cuda()\n",
    "# net eval mode\n",
    "net.eval()\n",
    "\n",
    "print('ready to evaluate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # count number of test points\n",
    "# n = 0 \n",
    "\n",
    "# # get img_ids from dataset\n",
    "# img_ids = np.array(test_dataset.img_ids) \n",
    "\n",
    "# # list for probs\n",
    "# all_probs = []\n",
    "\n",
    "# with torch.no_grad():\n",
    "# #     for n_iter, (images, labels, indices) in tqdm(enumerate(test_loader, 0), total=int(np.ceil(test_dataset.num / trainer.test_batch_size))):\n",
    "#     for n_iter, (images, labels, indices) in tqdm(enumerate(test_loader, 0), total=int(np.ceil(test_dataset.num / 4))):\n",
    "#         batch_size = len(images)\n",
    "#         n += batch_size\n",
    "#         if trainer.gpu_flag:\n",
    "#             images = images.cuda()\n",
    "\n",
    "# #         outputs = net(images)\n",
    "#         outputs, _ = forward_pass(images, net)\n",
    "#         logits = outputs\n",
    "\n",
    "#         probs = trainer.logits_to_probs(logits.data)\n",
    "#         all_probs += probs.cpu().numpy().reshape(-1).tolist() # collect all probs\n",
    "\n",
    "# # save probability vectors\n",
    "# all_probs = np.array(all_probs).reshape(-1, trainer.num_classes) # all_probs is an array of n-by-num_classes\n",
    "# if trainer.save_probs:\n",
    "#     np.save(trainer.result_prob_fname, all_probs)\n",
    "\n",
    "# # save predicted labels\n",
    "# df = prob_to_result(all_probs, img_ids) # prob_to_result located in net/loss_funcs/kaggle_metric.py; output pd.dataframe of img_ids and pred_list\n",
    "# df.to_csv(trainer.result_csv_file, index=False, compression='gzip')\n",
    "\n",
    "# # get F1-score\n",
    "# truth = pd.read_csv(trainer.test_split_file)\n",
    "# score = get_probs_f1_score(df, all_probs, truth, th=0.5)\n",
    "\n",
    "# print('macro f1 score:%.5f' % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_results = df.copy()\n",
    "# pred_results['Target'] = truth['Target'].values\n",
    "# pred_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CD score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:14<00:00,  1.01s/it]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for n_iter, (images, labels, indices) in tqdm(enumerate(test_loader, 0), total=int(np.ceil(test_dataset.num / test_batch_size))):\n",
    "        pass\n",
    "\n",
    "images = images[-2:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # input tensor\n",
    "# inputs = images.clone().detach()\n",
    "\n",
    "# # set up blobs\n",
    "# blob = torch.bernoulli(torch.empty(inputs.size()).uniform_(0, 1))\n",
    "\n",
    "# # compute cd scores\n",
    "# relevant, irrelevant, scores = cd_densenet(blob, inputs, net)\n",
    "\n",
    "# # forward pass\n",
    "# output, outputs = forward_pass(inputs, net)\n",
    "\n",
    "# # check the result\n",
    "# for i in range(len(outputs)):\n",
    "#     print(torch.norm(scores[i][0] + scores[i][1] - outputs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " iterations (channel,height,width) = (3, 11, 22)"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-ba1f2521e2f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mblob\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msuperpixel_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msuperpixel_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msuperpixel_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msuperpixel_size\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mrelevant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mirrelevant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcd_densenet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelevant\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mirrelevant\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1e-3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/HPA/hpa_interp/CD/cd.py\u001b[0m in \u001b[0;36mcd_densenet\u001b[0;34m(blob, im_torch, model)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m# initial convolution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mrelevant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mirrelevant\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpropagate_init_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelevant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mirrelevant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmods\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelevant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mirrelevant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/HPA/hpa_interp/CD/cd_propagate.py\u001b[0m in \u001b[0;36mpropagate_init_conv\u001b[0;34m(relevant, irrelevant, init_modules, device)\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0mrelevant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mirrelevant\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpropagate_conv_linear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelevant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mirrelevant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_modules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0mrelevant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mirrelevant\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpropagate_batchnorm2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelevant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mirrelevant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_modules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m     \u001b[0mrelevant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mirrelevant\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpropagate_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelevant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mirrelevant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_modules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m     \u001b[0mrelevant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mirrelevant\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpropagate_pooling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelevant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mirrelevant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_modules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrelevant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mirrelevant\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/HPA/hpa_interp/CD/cd_propagate.py\u001b[0m in \u001b[0;36mpropagate_relu\u001b[0;34m(relevant, irrelevant, activation, device)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mzeros\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelevant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0mrel_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelevant\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mirrel_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelevant\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mirrelevant\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelevant\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# relevant scores\n",
    "n = 0\n",
    "\n",
    "img_resize = 1024\n",
    "superpixel_size = 32\n",
    "h_num, w_num = int(img_resize/superpixel_size), int(img_resize/superpixel_size)\n",
    "\n",
    "rel_scores = torch.zeros(len(images), in_channels, img_resize, img_resize, NUM_CLASSES)\n",
    "\n",
    "with torch.no_grad():\n",
    "    batch_size = len(images)\n",
    "    n += batch_size\n",
    "    for c, h, w in itertools.product(range(in_channels), range(h_num), range(w_num)):\n",
    "        if h < 50 and w < 50:\n",
    "            # set up blobs\n",
    "            blob = torch.zeros(images.size())\n",
    "            blob[:,c,h*superpixel_size:(h+1)*superpixel_size,w*superpixel_size:(w+1)*superpixel_size] = 1\n",
    "\n",
    "            relevant, irrelevant, _ = cd_densenet(blob, images, net)\n",
    "            output, _ = forward_pass(images, net)\n",
    "            if torch.norm(relevant + irrelevant - output) > 1e-3:\n",
    "                print('sum of cd scores do not match the original ouput at (channel,height,width) =', (c,h,w))\n",
    "\n",
    "            rel_scores[:,c,h*superpixel_size:(h+1)*superpixel_size, \n",
    "                            w*superpixel_size:(w+1)*superpixel_size,:] = relevant[:,None,None,:]\n",
    "\n",
    "        print('\\r iterations (channel,height,width) =', (c,h,w), end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load saved files\n",
    "# with open('images1.pkl','rb') as file:\n",
    "#     images1 = pkl.load(file)\n",
    "# with open('cd_scores1.pkl','rb') as file:\n",
    "#     rel_scores1 = pkl.load(file)\n",
    "# with open('images2.pkl','rb') as file:\n",
    "#     images2 = pkl.load(file)\n",
    "# with open('cd_scores2.pkl','rb') as file:\n",
    "#     rel_scores2 = pkl.load(file)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_index, label_index = 0, 27\n",
    "viz.viz_channels_separate(images, img_index, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_index, label_index = 0, 5\n",
    "viz.viz_channels_separate(images, img_index, None, rel_scores, label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images.cpu().numpy()\n",
    "rel_scores = rel_scores.cpu().numpy()\n",
    "with open('images_32_by_32.pkl','wb') as file:\n",
    "    pkl.dump(images, file)\n",
    "with open('cd_scores_32_by_32.pkl','wb') as file:\n",
    "    pkl.dump(rel_scores, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'method' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-059f7554c790>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'method' object is not iterable"
     ]
    }
   ],
   "source": [
    "list(net.modules.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
